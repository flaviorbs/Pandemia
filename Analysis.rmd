---
title: "Pandemia"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages}

# General
require(tidyverse) # Unidos de Hadley
library(janitor)
library(lubridate)
library(hms)
library(readr)

# Analise Exploratoria dos data-frames
library(skimr)

# Scraping
require(httr)
library(rvest)
library(xml2)

# NLP
library(tidytext)
```

Para todos os casos utilizei o rvest, pacote de scraping do r.

Também utilizei o [SelectorGadget](https://selectorgadget.com/) para identificar como trazer blocos de CSS para dentro do R.

Estruturei o trabalho da seguinte maneira: 
1. Baixo as notas taquigráficas para:
  + tentar identifcar quem falava 
  + fazer outras análizes de texto
2. Processo um banco com a audiência absoluta dos canais que transmitiram a CPI
3. Analiso o impacto 


# Carregando os dados do Senado

## Notas Taquigráficas do Senado.
 
Da [Página da CPI](https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-17&data2=2021-10-17) é possível extrair os dados das reuniões e acessar as notas taquigráficas de todas as sessões.

Aqui as notas da [primeira reunião](https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/9956). 

Essas notas são na verdade geradas por uma aplicação e podem ser acessadas em páginas HTML sem  [formatação](https://www25.senado.leg.br/web/atividade/notas-taquigraficas?p_p_id=escriba_WAR_atividadeportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1&_escriba_WAR_atividadeportlet_cr=9956).

Já sabemos quando ocorreram as sessões públicas e temos como extrair as notas taquigráficas

## Explorando as Notas Taquigráficas

Começo importando uma página de notas taquigráficas de uma sessão. Aqui eu escolhi a sessão [16/09/2021 - 55ª - CPI da Pandemia](https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/10242):

```{r}
ex_nt <- read_html("https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/10111")

```


Por meio de uma função simples, consigo abrir essa página, idenficar um iframe que é chamado

```{r}

ex_nt_0 <- ex_nt  %>% 
  html_nodes(".escriba-jq") %>% 
  html_attr("data-url")
  # Dá para ver que as notas taquigráficas são chamadas em uma URL

ex_nt_0

```


Aqui uma versão "limpa" da tabela:

```{r}

ex_nt_1 <- ex_nt_0 %>% 
  read_html() %>% 
  html_table() %>% 
  .[[1]] %>% 
  clean_names() %>% 
  mutate(horario = hm(horario, quiet = TRUE)) %>% 
  filter(!is.na(horario)) %>% 
  mutate(horario = hms(horario))

ex_nt_1 

```

E se eu quiser, posso inclusive extrair a URL do audio do trecho da transcrição e adicionar uma coluna ao lado da transcrição com o audio referente ao trecho.

Nesse processo, descobri que as URL do áudio já vem com a data e hora da gravação, ótimo.

```{r}

ex_nt_2 <- ex_nt_1  %>% 
  cbind(., 
        audio = ex_nt %>% 
                  html_nodes("#tabelaQuartos") %>%
                  html_nodes("tr") %>%
                  html_nodes("a") %>%
                  html_attr("href") %>% 
                  str_match("\\'(.*?)\\'") %>% 
                  .[,2] %>% 
                  .[!is.na(.)]) %>% 
  rowwise %>% 
  mutate(data = as_date(str_sub(audio, start = -19, end = -12), format = "%Y%m%d"),
         #hora = str_sub(audio, start = -6) %>% strsplit(., "(?<=.{2})", perl = TRUE)[[1]] %>% paste(collapse = ":") %>% as_hms,
         hora_inicio = as_hms(paste(strsplit(str_sub(audio, start = -6), "(?<=.{2})", perl = TRUE)[[1]], collapse = ":"))
         )

ex_nt_2

```

Aqui eu explodo os blocos de transcrição (que duram em média 4min) para ter cada frase isoladamente.

```{r}

ex_nt_3 <- ex_nt_2  %>% 
  unnest_tokens(texto_com_revisao_b, texto_com_revisao, token = "regex", pattern = "\\\n", to_lower = FALSE)

ex_nt_3

```

Posso, por último, identificar quem estava com a palavra, isolar a transcrição apenas.

```{r}

ex_nt_4 <- ex_nt_3 %>%
  rowwise() %>%
      mutate(
        orador = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            str_locate(texto_com_revisao_b, "SR")[1],
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 120), "\\) \\– ")[2] - 3,
              str_locate(str_sub(texto_com_revisao_b, 1, 50), "[A-Z][A-Z][A-Z][A-Z] – ")[1] + 3
            )
          )
        } else {
          NA
        },
        fala = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "\\) \\– ")[2],
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "[:upper:][:upper:][:upper:][:upper:] – ")[2]
            ),
            str_length(texto_com_revisao_b)
          )
        } else {
          texto_com_revisao_b
        }
      ) %>%
      ungroup() %>%
      fill(orador, .direction = "down")
  
```

Agora já consigo extrair bastante dado. 

Vou terminar a manipulação depois que conseguir empilhar todas as notas de todas as sessões.

```{r}
rm(list=ls(pattern="ex_nt"))
```


## Explorando a lista de Sessões da CPI

Começo trazendo a [lista se sessões](https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-01&data2=2021-11-01) para dentro do r a página

```{r}
web_pandemia <- read_html("https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-01&data2=2021-11-01")
```

Quando se trata dessa lista, como os dados estão organizados em DIV e não em tabelas HTML, preferi criar um tibble a partir de vetores com os elementos que quero que constem no meu estudo.

De novo, a ferramenta [SelectorGadget](https://selectorgadget.com/) é a melhor opção para extrair os nodes que serão passados ao rvest, transformados em vetores e depois em tibbles.

Aqui eu já identifico que cada reunião da comissão tem um id e é ele que uso para construir a URL onde eu espero encontrar as notas taquigráficas.


```{r}
meetings <- tibble(
  data = web_pandemia %>% html_nodes("a:nth-child(1) span:nth-child(1)") %>% html_text %>% readr::parse_date(format="%d/%m/%Y") %>% na.omit(.),
  titulo = web_pandemia %>% html_nodes(".ajuste-resultado-agenda span:nth-child(2)") %>% html_text(),
  status = web_pandemia %>% html_nodes(".bold span") %>% html_text(),
  tema = web_pandemia %>% html_nodes(".f2") %>% html_text(),
  id = web_pandemia %>% html_nodes("strong a") %>% html_attr("href") %>% str_match("reuniao\\=\\s*(.*?)\\s*\\&") %>% .[,2] %>% unique()
) %>% 
  mutate(escriba_url = paste0("https://www25.senado.leg.br/web/atividade/notas-taquigraficas?p_p_id=escriba_WAR_atividadeportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1&_escriba_WAR_atividadeportlet_cr=", id)
  )

meetings %>% 
  arrange(data)
```

## Brincando de Programação Funcional apra juntar tudo

Primeiro vou tentar criar uma função que proceda todas as transformações que fiz nas notas taquigráficas utilizando o exemplo acima:

```{r}
read_nt <- function(escriba_url) {
  # O arquivo de Nota taquigráfica está em branco?
  if (read_html(escriba_url) %>% html_nodes("#tabelaQuartos") %>% length() == 0) {
    # Se sim, então joga um NA
    NA
  }
  # Se não, aplica as transformações que exercitamos na Exploração das notas taquigráficas
  else {
    # ex_nt - Baixa a Página
    read_html(escriba_url) %>%
      # ex_nt_0 - Acha a tabela com os blocos de transcrição
      html_nodes("#tabelaQuartos") %>%
      html_table() %>%
      # ex_nt_1 - Abre a Tabela
      .[[1]] %>%
      clean_names() %>%
      mutate(horario = hm(horario, quiet = TRUE)) %>%
      filter(!is.na(horario)) %>%
      mutate(horario = hms(horario)) %>% 
    # ex_nt_2 - Incorpora a URL de audio e extrai a data e hora do bloco
    cbind(.,
      audio = read_html(escriba_url) %>%
        html_nodes("#tabelaQuartos") %>%
        html_nodes("tr") %>%
        html_nodes("a") %>%
        html_attr("href") %>%
        str_match("\\'(.*?)\\'") %>%
        .[, 2] %>%
        .[!is.na(.)]
    ) %>%
      rowwise() %>%
      mutate(
        data = as_date(str_sub(audio, start = -19, end = -12), format = "%Y%m%d"),
        hora_inicio = as_hms(paste(strsplit(str_sub(audio, start = -6), "(?<=.{2})", perl = TRUE)[[1]], collapse = ":"))
      ) %>%
      # ex_nt_3 - Explode os parágrafos dos blocos
      unnest_tokens(texto_com_revisao_b, texto_com_revisao, token = "regex", pattern = "\\\n", to_lower = FALSE) %>%
      # ex_nt_4 - Ajusta os textos (orador, comentário e fala)
      rowwise() %>%
      mutate(
        orador = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            str_locate(texto_com_revisao_b, "SR")[1],
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 120), "\\) \\– ")[2] - 3,
              str_locate(str_sub(texto_com_revisao_b, 1, 50), "[A-Z][A-Z][A-Z][A-Z] – ")[1] + 3
            )
          )
        } else {
          NA
        },
        fala = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "\\) \\– ")[2],
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "[:upper:][:upper:][:upper:][:upper:] – ")[2]
            ),
            str_length(texto_com_revisao_b)
          )
        } else {
          texto_com_revisao_b
        }
      ) %>%
      ungroup() %>%
      fill(orador, .direction = "down")
  }
}
```


Agora eu tento aplicar essa função na lista de sessões que preparei.

Atenção: Esse processo é meio lento, ele carrega pagina por pagina do Senado. Além disso, o Senado pode se incomodar com a metralhadora de acessos que o r gera e achar que estamos fazendo um ataque DOS...

```{r}

full_meetings <- meetings %>% 
  mutate(nota = map(escriba_url, read_nt))

```


Temos agora uma lista das reuniões e suas respectivas notas taquigráficas. Podemos explodir esse arquivo e ver cada parágrafo das notas taquigráficas de toda a CPI, os oradores, o que foi dito e os horários estimados em que o orador/depoente discursava

## Empilhando e limpando as notas taquigráficas

Esse script ficou super grande e certamente pouco eficiente. Depois de fazer o "unnest" das notas taquigráficas eu fui fazendo os ajustes passo a passo, linha a linha e, a cada passo, fui jogando no skimr e checando os erros, NA, incosistências. Trabalho chato que durou umas 4 horas (pode chamar de Feature Engineering, mas eu chamo de pelação de saco). 

Ao terminar, estava sem saco de otimizar e esculpir melhor esse script.

Também fiquei na dúvida se não deveria jogar parte desses mutates para a função que traz os arquivos.

```{r}

full_notas <- full_meetings %>%
  rename(data_meeting = data) %>%
  unnest(cols = c(nota)) %>%
  rename(bloco_escriba = horario) %>%
  filter(!is.na(bloco_escriba)) %>%
  select(-nota) %>%
  rowwise() %>%
  mutate(
    comentario = str_extract(orador, "(?<=\\()[^()]+(?=\\))"),
    orador = str_remove_all(orador, "SR. |SRA. | \\s*\\([^\\)]+\\)"),
    intervalo = str_detect(texto_com_revisao_b, "\\(Suspensa às"),
    hora_inicio = hms(ifelse(intervalo,
      max(hms(hm(str_extract(texto_com_revisao_b, "(?<=Suspensa às )[^()]+(?=\\,)"), quiet = TRUE)), hora_inicio + as.duration("5 seconds")),
      hora_inicio
    )),
    npalavras = str_count(str_remove_all(fala, "\\s*\\([^\\)]+\\)"), "\\W+")
  ) %>%
  ungroup() %>%
  filter(!is.na(hora_inicio)) %>%
  group_by(data_meeting) %>%
  mutate(
    hora_fim = coalesce(rep(lead(unique(hora_inicio)), table(hora_inicio)), hora_inicio + as.duration("4 minutes"))
  ) %>%
  rowwise() %>%
  group_by(data, hora_inicio) %>%
  mutate(
    duracao = (hora_fim - hora_inicio) * replace_na(npalavras / sum(npalavras), 1),
    posicao = (hora_fim - hora_inicio) * replace_na(cumsum(replace_na(lag(npalavras), 0)) / sum(npalavras), 0)
  ) %>%
  ungroup() %>%
  mutate(
    hora_inicio = round_hms(as_hms(hora_inicio + posicao), digits = 0),
    hora_fim = round_hms(as_hms(hora_inicio + duracao), digits =0)
  ) %>%
  arrange(data, hora_inicio) %>%
  select(titulo, tema, data, hora_inicio, hora_fim, intervalo, duracao, orador, comentario, fala, audio)

# skim(full_notas)

```


# Carregando os dados de Audiencia
Aqui uso uma base de dados brutas do Ibope. Essa base tem os dados do painel da Kantar Ibope Media e me diz quantas pessoas estavam sintonizadas em cada canal minuto a minuto. Isolei as variárivel Total TV, que conta todos os aparelhos de TV ligados nos 15 mercados do PNT e os canais GloboNews e CNN.

Essa base do Ibope é confidencial.

```{r}
convert.to.sec <- function(X) {
  X <- strsplit(X, ":")
  sapply(X, function(Y) sum(as.numeric(Y) * c(3600, 60, 1)))
}

ratings <- read_csv("raw_data/news_ratings.csv", 
                    col_names = c("channel", "data", "hora", "trp", "abs"),
                    col_types = cols(data = col_date(format = "%Y-%m-%d"),
                                     hora = col_character()), 
                    skip = 3) %>% 
  mutate(datahora = data + seconds(convert.to.sec(hora)),
         data = date(datahora),
         hora = as_hms(paste(hour(datahora),minute(datahora),"00", sep = ":"))) %>% 
  pivot_wider(id_cols = c("data", "hora"), names_from = channel, values_from = abs)



```





# Analise Preliminar dos Dados

### As Sessões
```{r}
full_notas %>% 
  arrange(data) %>% 
  group_by(as_factor(titulo)) %>% 
  filter(intervalo == FALSE) %>% 
  summarise(n = n(),
            hora_inicio = as_hms(min(hora_inicio)),
            hora_fim = as_hms(max(hora_fim)),
            tempo = as.duration(hora_fim - hora_inicio),
            duracao = as.duration(sum(duracao))) 

```


E essa "10ª, Reunião - Semipresencial" que durou mais que um dia?
```{r}

full_notas %>%  
  filter(titulo == "10ª, Reunião - Semipresencial") %>% 
  View()


full_notas %>% 
  filter(str_detect(fala, "\\(Suspensa às")) %>% 
  select(datahora, fala) %>% 
  mutate(inicio = hm(str_extract(fala, "(?<=Suspensa às )[^()]+(?=\\,)")),
         fim = hm(str_extract(fala, "(?<=reaberta às )[^()]+(?=\\.|\\))"))) %>% 
  filter(!is.na(inicio)|!is.na(fim))


```



### Quem falou mais

```{r}

full_notas %>% 
  filter(str_detect(orador,"PRESIDENTE")) %>% 
  group_by(orador, comentario) %>% 
  summarise(duracao = as.duration(sum(duracao))) %>% 
  arrange(desc(duracao))

```


```{r}

full_notas %>% 
  arrange(data)
  filter(str_detect(orador,"PRESIDENTE")) %>% 
  group_by(orador, comentario) %>% 
  summarise(duracao = as.duration(sum(duracao))) %>% 
  arrange(desc(duracao))

```


Pegando as datas para a geração de um export de audiência
```{r}



```

