---
title: "Pandemia"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r packages}

# General
require(tidyverse) # Unidos de Hadley
library(janitor)
library(lubridate)
library(hms)

library(skimr)

# Scraping
require(httr)
library(rvest)
library(xml2)

# NLP
library(tidytext)
```

Para todos os casos utilizei o rvest, pacote de scraping do r.

Também utilizei o [SelectorGadget](https://selectorgadget.com/) para identificar como trazer blocos de CSS para dentro do R.

Estruturei o trabalho da seguinte maneira: 
1. Baixo as notas taquigráficas para:
  + tentar identifcar quem falava 
  + fazer outras análizes de texto
2. Processo um banco com a audiência absoluta dos canais que transmitiram a CPI
3. Analiso o impacto 


# Carregando os dados do Senado

## Notas Taquigráficas do Senado.
 
Da [Página da CPI](https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-17&data2=2021-10-17) é possível extrair os dados das reuniões e acessar as notas taquigráficas de todas as sessões.

Aqui as notas da [primeira reunião](https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/9956). 

Essas notas são na verdade geradas por uma aplicação e podem ser acessadas em páginas HTML sem  [formatação](https://www25.senado.leg.br/web/atividade/notas-taquigraficas?p_p_id=escriba_WAR_atividadeportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1&_escriba_WAR_atividadeportlet_cr=9956).

Já sabemos quando ocorreram as sessões públicas e temos como extrair as notas taquigráficas

## Explorando as Notas Taquigráficas

Começo importando uma página de notas taquigráficas de uma sessão. Aqui eu escolhi a sessão [16/09/2021 - 55ª - CPI da Pandemia](https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/10242):

```{r}
ex_nt <- read_html("https://www25.senado.leg.br/web/atividade/notas-taquigraficas/-/notas/r/10111")

```


Por meio de uma função simples, consigo abrir essa página, idenficar a página simplificada que é chamada dentro dessa e transformar a tabela do Escriba em um tibble:

```{r}

ex_nt_0 <- ex_nt  %>% 
  html_nodes(".escriba-jq") %>% 
  html_attr("data-url") %>% 
  read_html() %>% 
  html_nodes("#tabelaQuartos") %>% 
  html_table()

ex_nt_0

```




Aqui uma versão "limpa" da tabela:

```{r}

ex_nt_0 <- read_html("https://www25.senado.leg.br/web/atividade/notas-taquigraficas?p_p_id=escriba_WAR_atividadeportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1&_escriba_WAR_atividadeportlet_cr=10111") %>% 
  html_nodes("#tabelaQuartos") %>% 
  html_table()


ex_nt_1 <-  ex_nt_0 %>% 
  .[[1]] %>% 
  clean_names() %>% 
  mutate(horario = hm(horario, quiet = TRUE)) %>% 
  filter(!is.na(horario)) %>% 
  mutate(horario = hms(horario))

ex_nt_1 

```

E se eu quiser, posso inclusive extrair a URL do audio do trecho da transcrição e adicionar uma coluna ao lado da transcrição com o audio referente ao trecho.

Nesse processo, descobri que as URL do áudio já vem com a data e hora da gravação, ótimo.

```{r}

ex_nt_2 <- ex_nt_1  %>% 
  cbind(., 
        audio = ex_nt %>% 
                  html_nodes("#tabelaQuartos") %>%
                  html_nodes("tr") %>%
                  html_nodes("a") %>%
                  html_attr("href") %>% 
                  str_match("\\'(.*?)\\'") %>% 
                  .[,2] %>% 
                  .[!is.na(.)]) %>% 
  rowwise %>% 
  mutate(data = as_date(str_sub(audio, start = -19, end = -12), format = "%Y%m%d"),
         #hora = str_sub(audio, start = -6) %>% strsplit(., "(?<=.{2})", perl = TRUE)[[1]] %>% paste(collapse = ":") %>% as_hms,
         hora_inicio = as_hms(paste(strsplit(str_sub(audio, start = -6), "(?<=.{2})", perl = TRUE)[[1]], collapse = ":"))
         )

ex_nt_2

```

Posso também contar quanto tempo durou cada bloco de transcrição (aparentemente a Escriba quebra em blocos de 4 minutos). Como cada bloco pode ter mais de um orador, também posso explodir os parágrafos de cada bloco.

```{r}

ex_nt_3 <- ex_nt_2  %>% 
  unnest_tokens(texto_com_revisao_b, texto_com_revisao, token = "regex", pattern = "\\\n", to_lower = FALSE)

ex_nt_3

```

Posso, por último, identificar quem estava com a palavra, isolar a transcrição apenas e ajustar as horas de acordo com a proporção de texto o de cada bloco.

```{r}

ex_nt_4 <- ex_nt_3 %>%
  rowwise() %>%
  mutate(
    orador = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
      str_sub(
        texto_com_revisao_b,
        str_locate(texto_com_revisao_b, "SR")[1],
        coalesce(
          str_locate(str_sub(texto_com_revisao_b, 1, 100), "\\) \\– ")[2] - 3,
          str_locate(str_sub(texto_com_revisao_b, 1, 50), "[A-Z][A-Z][A-Z][A-Z] – ")[1] + 3
        )
      )
    } else {
      NA
    },
    fala = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
      str_sub(
        texto_com_revisao_b,
        coalesce(
          str_locate(str_sub(texto_com_revisao_b, 1, 200), "\\) \\– ")[2],
          str_locate(str_sub(texto_com_revisao_b, 1, 200), "[A-Z][A-Z][A-Z][A-Z] – ")[2]
        ),
        str_length(texto_com_revisao_b)
      )
    } else {
      texto_com_revisao_b
    }
  ) %>%
  # Agora desativo o row-wise e preencho os dados do orador nos parágrafos vazios
  ungroup() %>%
  fill(orador, .direction = "down") %>%
  rowwise() %>%
  # Agora faço o split de orador entre o nome do orador/depoente e os comentários atrelados.
  mutate(
    comentario = str_extract(orador, "(?<=\\()[^()]+(?=\\))"),
    orador = str_remove_all(orador, "SR. |SRA. | \\s*\\([^\\)]+\\)"))
  
```


```{r}

ex_nt_5 <- ex_nt_4 %>% 
  mutate(
    intervalo = str_detect(texto_com_revisao_b, "\\(Suspensa às"),
    hora_inicio = hms(ifelse(intervalo, 
                             hms(hm(str_extract(texto_com_revisao_b, "(?<=Suspensa às )[^()]+(?=\\,)"))),
                             hora_inicio)),
    npalavras = str_count(str_remove_all(fala, "\\s*\\([^\\)]+\\)"), "\\W+")
  ) %>% 
  ungroup %>% 
    mutate(
      hora_fim = rep(lead(unique(hora_inicio)), table(hora_inicio)),
      ) %>%
  rowwise %>% 
  mutate(hora_fim = replace_na(hora_fim, hora_inicio + as.duration("4 minutes"))
         ) %>% 
  group_by(hora_inicio) %>%
  mutate(duracao = (hora_fim - hora_inicio) * replace_na(npalavras/sum(npalavras),1),
         posicao = (hora_fim - hora_inicio) * replace_na(cumsum(replace_na(lag(npalavras),0)) / sum(npalavras),0)
         ) %>% 
  ungroup %>% 
  mutate(
    hora_inicio = hms::as_hms(hora_inicio + posicao),
    hora_fim = hms::as_hms(hora_inicio + duracao)
    ) %>% 
  select(data, hora_inicio, hora_fim, duracao, intervalo, orador, comentario, fala, audio, bloco_escriba = horario)
  
ex_nt_5

```

Ouvindo o audio de alguns trechos, fica claro que a marcação proporcional ao número de palavras não é precisa, especialmente no começo da sessão, mas é o melhor que temos por hora.

## Explorando a lista de Sessões da CPI

Começo trazendo a [lista se sessões](https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-01&data2=2021-11-01) para dentro do r a página
```{r}
web_pandemia <- read_html("https://legis.senado.leg.br/comissoes/comissao?codcol=2441&data1=2021-03-01&data2=2021-11-01")
```

Quando se trata dessa lista, como os dados estão organizados em DIV e não em tabelas HTML, preferi criar um tibble a partir de vetores com os elementos que quero que constem no meu estudo.

De novo, a ferramenta [SelectorGadget](https://selectorgadget.com/) é a melhor opção para extrair os nodes que serão passados ao rvest, transformados em vetores e depois em tibbles.

Aqui eu já identifico que cada reunião da comissão tem um id e é ele que uso para construir a URL onde eu espero encontrar as notas taquigráficas.


```{r}
meetings <- tibble(
  data = web_pandemia %>% html_nodes("a:nth-child(1) span:nth-child(1)") %>% html_text %>% readr::parse_date(format="%d/%m/%Y") %>% na.omit(.),
  titulo = web_pandemia %>% html_nodes(".ajuste-resultado-agenda span:nth-child(2)") %>% html_text(),
  status = web_pandemia %>% html_nodes(".bold span") %>% html_text(),
  tema = web_pandemia %>% html_nodes(".f2") %>% html_text(),
  id = web_pandemia %>% html_nodes("strong a") %>% html_attr("href") %>% str_match("reuniao\\=\\s*(.*?)\\s*\\&") %>% .[,2] %>% unique()
) %>% 
  mutate(escriba_url = paste0("https://www25.senado.leg.br/web/atividade/notas-taquigraficas?p_p_id=escriba_WAR_atividadeportlet&p_p_lifecycle=2&p_p_state=normal&p_p_mode=view&p_p_cacheability=cacheLevelPage&p_p_col_id=column-1&p_p_col_count=1&_escriba_WAR_atividadeportlet_cr=", id)
  )

meetings %>% 
  arrange(data)
```

## Brincando de Programação Funcional apra juntar tudo

Primeiro vou tentar criar uma função que proceda todas as transformações que fiz nas notas taquigráficas utilizando o exemplo acima:

```{r}
read_nt <- function(escriba_url) {
  # O arquivo de Nota taquigráfica está em branco?
  if (read_html(escriba_url) %>% html_nodes("#tabelaQuartos") %>% length() == 0) {
    # Se sim, então joga um NA
    NA
  }
  # Se não, aplica as transformações que exercitamos na Exploração das notas taquigráficas
  else {
    # ex_nt - Baixa a Página
    read_html(escriba_url) %>%
      # ex_nt_0 - Acha a tabela com os blocos de transcrição
      html_nodes("#tabelaQuartos") %>%
      html_table() %>%
      # ex_nt_1 - Abre a Tabela
      .[[1]] %>%
      clean_names() %>%
      mutate(horario = hm(horario, quiet = TRUE)) %>%
      filter(!is.na(horario)) %>%
      mutate(horario = hms(horario)) %>% 
    # ex_nt_2 - Incorpora a URL de audio e extrai a data e hora do bloco
    cbind(.,
      audio = read_html(escriba_url) %>%
        html_nodes("#tabelaQuartos") %>%
        html_nodes("tr") %>%
        html_nodes("a") %>%
        html_attr("href") %>%
        str_match("\\'(.*?)\\'") %>%
        .[, 2] %>%
        .[!is.na(.)]
    ) %>%
      rowwise() %>%
      mutate(
        data = as_date(str_sub(audio, start = -19, end = -12), format = "%Y%m%d"),
        hora_inicio = as_hms(paste(strsplit(str_sub(audio, start = -6), "(?<=.{2})", perl = TRUE)[[1]], collapse = ":"))
      ) %>%
      # ex_nt_3 - Explode os parágrafos dos blocos
      unnest_tokens(texto_com_revisao_b, texto_com_revisao, token = "regex", pattern = "\\\n", to_lower = FALSE) %>%
      # ex_nt_4 - Ajusta os textos (orador, comentário e fala)
      rowwise() %>%
      mutate(
        orador = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            str_locate(texto_com_revisao_b, "SR")[1],
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 120), "\\) \\– ")[2] - 3,
              str_locate(str_sub(texto_com_revisao_b, 1, 50), "[A-Z][A-Z][A-Z][A-Z] – ")[1] + 3
            )
          )
        } else {
          NA
        },
        fala = if (!is.na(str_locate(str_sub(texto_com_revisao_b, 1, 5), "SR")[1])) {
          str_sub(
            texto_com_revisao_b,
            coalesce(
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "\\) \\– ")[2],
              str_locate(str_sub(texto_com_revisao_b, 1, 200), "[:upper:][:upper:][:upper:][:upper:] – ")[2]
            ),
            str_length(texto_com_revisao_b)
          )
        } else {
          texto_com_revisao_b
        }
      ) %>%
      ungroup() %>%
      fill(orador, .direction = "down")
  }
}
```



```{r}
%>%
      # ex_nt_5 - Ajusta as horas
      mutate(
        intervalo = str_detect(texto_com_revisao_b, "\\(Suspensa às"),
        hora_inicio = hms(ifelse(intervalo,
          hms(hm(str_extract(texto_com_revisao_b, "(?<=Suspensa às )[^()]+(?=\\,)"))),
          hora_inicio
        )),
        npalavras = str_count(str_remove_all(fala, "\\s*\\([^\\)]+\\)"), "\\W+")
      ) %>%
      ungroup() %>%
      mutate(
        hora_fim = rep(lead(unique(hora_inicio)), table(hora_inicio)),
      ) %>%
      rowwise() %>%
      mutate(hora_fim = replace_na(hora_fim, hora_inicio + as.duration("4 minutes"))) %>%
      group_by(hora_inicio) %>%
      mutate(
        duracao = (hora_fim - hora_inicio) * replace_na(npalavras / sum(npalavras), 1),
        posicao = (hora_fim - hora_inicio) * replace_na(cumsum(replace_na(lag(npalavras), 0)) / sum(npalavras), 0)
      ) %>%
      ungroup() %>%
      mutate(
        hora_inicio = hms::as_hms(hora_inicio + posicao),
        hora_fim = hms::as_hms(hora_inicio + duracao)
      )
```


Agora eu tento aplicar essa função na lista de sessões que preparei.

Atenção: Esse processo é meio lento, ele carrega pagina por pagina do Senado. Além disso, o Senado por achar que estamos fazendo um ataque DOS...

```{r}

full_meetings <- meetings %>% 
  mutate(nota = map(escriba_url, read_nt))

```


Temos agora uma lista das reuniões e suas respectivas notas taquigráficas. Podemos explodir esse arquivo e ver cada parágrafo das notas taquigráficas de toda a CPI, os oradores, o que foi dito e os horários estimados em que o orador/depoente discursava

```{r}

full_notas <- full_meetings %>% 
  rename(data_meeting = data) %>% 
  unnest(cols = c(nota)) %>% 
  rename(bloco_escriba = horario) %>% 
  filter(!is.na(bloco_escriba)) %>% 
  select(-nota)

#skim(full_notas)

full_notas_a <-full_notas %>%
  rowwise() %>%
  mutate(
    comentario = str_extract(orador, "(?<=\\()[^()]+(?=\\))"),
    orador = str_remove_all(orador, "SR. |SRA. | \\s*\\([^\\)]+\\)"),
    intervalo = str_detect(texto_com_revisao_b, "\\(Suspensa às"),
    hora_inicio = hms(ifelse(intervalo,
      max(hms(hm(str_extract(texto_com_revisao_b, "(?<=Suspensa às )[^()]+(?=\\,)"), quiet = TRUE)), hora_inicio + as.duration("5 seconds")),
      hora_inicio
    )),
    npalavras = str_count(str_remove_all(fala, "\\s*\\([^\\)]+\\)"), "\\W+")
  ) %>% 
  ungroup() %>% 
  filter(!is.na(hora_inicio))

#skim(full_notas_a)

full_notas_b <-full_notas_a %>% 
  group_by(data_meeting) %>% 
  mutate(
        hora_fim = coalesce(rep(lead(unique(hora_inicio)), table(hora_inicio)), hora_inicio + as.duration("4 minutes"))
      )

#skim(full_notas_b %>% ungroup)

full_notas_c <- full_notas_b %>% 
  rowwise() %>%
  group_by(data, hora_inicio) %>%
  mutate(
    duracao = (hora_fim - hora_inicio) * replace_na(npalavras / sum(npalavras), 1),
    posicao = (hora_fim - hora_inicio) * replace_na(cumsum(replace_na(lag(npalavras), 0)) / sum(npalavras), 0)
  )

#skim(full_notas_c %>% ungroup)

full_notas_d <- full_notas_c %>% 
  ungroup() %>%
  mutate(
    hora_inicio = hms::as_hms(hora_inicio + posicao),
    hora_fim = hms::as_hms(hora_inicio + duracao)
  )

#skim(full_notas_d %>% ungroup)


full_notas_d %>% 
  filter(duracao <0)

full_notas_b %>% 
  filter(id == 10190 & bloco_escriba >= as_hms("12:14:00"))

full_notas_d %>% 
  filter(id == 10190 & bloco_escriba >= as_hms("12:14:00"))

  mutate(datahora = as_datetime(data) + horario) %>% # criando uma coluna com a data e a hora
  select(titulo, tema, datahora, orador, comentario, fala, audio, duracao, data, bloco) %>% 
  arrange(datahora) %>% 
  mutate_if(is.character, str_trim)

```

# Analise Preliminar dos Dados

### As Sessões
```{r}
full_notas %>% 
  group_by(titulo) %>% 
  summarise(n = n(),
            inicio = min(datahora),
            fim = max(datahora),
            tempo = as.duration(max(datahora) - min(datahora)),
            duracao = as.duration(sum(duracao))) %>% 
  arrange(inicio)

```


E essa "10ª, Reunião - Semipresencial" que durou mais que um dia?
```{r}

full_notas %>%  
  filter(titulo == "10ª, Reunião - Semipresencial") %>% 
  View()


full_notas %>% 
  filter(str_detect(fala, "\\(Suspensa às")) %>% 
  select(datahora, fala) %>% 
  mutate(inicio = hm(str_extract(fala, "(?<=Suspensa às )[^()]+(?=\\,)")),
         fim = hm(str_extract(fala, "(?<=reaberta às )[^()]+(?=\\.|\\))"))) %>% 
  filter(!is.na(inicio)|!is.na(fim))


```



### Quem falou mais

```{r}

full_notas %>% 
  filter(str_detect(orador,"PRESIDENTE")) %>% 
  group_by(orador, comentario) %>% 
  summarise(duracao = as.duration(sum(duracao))) %>% 
  arrange(desc(duracao))

```


```{r}

full_notas %>% 
  arrange(data)
  filter(str_detect(orador,"PRESIDENTE")) %>% 
  group_by(orador, comentario) %>% 
  summarise(duracao = as.duration(sum(duracao))) %>% 
  arrange(desc(duracao))

```


Pegando as datas para a geração de um export de audiência
```{r}



```

